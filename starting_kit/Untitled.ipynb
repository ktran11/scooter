{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA(copy=True, iterated_power='auto', n_components=0.99, random_state=None,\n",
      "    svd_solver='auto', tol=0.0, whiten=False)\n",
      "[[0.75410028 0.30301895 0.98900366 ... 0.12811239 0.77311868 0.36164292]\n",
      " [0.23510662 0.26102436 0.27206591 ... 0.08188797 0.19414409 0.02080114]\n",
      " [0.9062137  0.60689342 0.27131143 ... 0.59153258 0.70880673 0.93681247]\n",
      " ...\n",
      " [0.81797223 0.35114514 0.71417223 ... 0.57409024 0.32069783 0.22534563]\n",
      " [0.09913789 0.70381395 0.58967634 ... 0.01240956 0.33986336 0.4661396 ]\n",
      " [0.97154176 0.17249508 0.46089476 ... 0.35721551 0.89477279 0.57620694]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np# We recommend to use numpy arrays\n",
    "from os.path import isfile\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import pandas as pd # for using pandas daraframe\n",
    "from sklearn.preprocessing import StandardScaler # for standardizing the Data\n",
    "from sklearn.feature_selection import GenericUnivariateSelect, f_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.base import BaseEstimator\n",
    "class model (BaseEstimator):\n",
    "\n",
    "    \n",
    "    def __init__(self):\n",
    "        '''\n",
    "        This constructor is supposed to initialize data members.\n",
    "        Use triple quotes for function documentation. \n",
    "        '''\n",
    "        self.num_train_samples= 38563\n",
    "        self.num_feat=59\n",
    "        self.num_labels=1\n",
    "        self.is_trained=False\n",
    "        self.preprocess = GenericUnivariateSelect(f_regression, 'k_best', param=self.num_feat)\n",
    "        self.mod = RandomForestRegressor(n_estimators=110, max_depth = 30,min_samples_split=5) \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        This function should train the model parameters.\n",
    "        Here we do nothing in this example...\n",
    "        Args:\n",
    "            X: Training data matrix of dim num_train_samples * num_feat.\n",
    "            y: Training label matrix of dim num_train_samples * num_labels.\n",
    "        Both inputs are numpy arrays.\n",
    "        For classification, labels could be either numbers 0, 1, ... c-1 for c classe\n",
    "        or one-hot encoded vector of zeros, with a 1 at the kth position for class k.\n",
    "        The AutoML format support on-hot encoding, which also works for multi-labels problems.\n",
    "        Use data_converter.convert_to_num() to convert to the category number format.\n",
    "        For regression, labels are continuous values.\n",
    "        '''\n",
    "        norm = np.linalg.norm(X)\n",
    "        pca = PCA(0.99)\n",
    "        pca.fit(X/norm)\n",
    "        x_pca =pca. transform(X/norm)\n",
    "        print(pca)\n",
    "        if (not self.is_trained):\n",
    "            self.num_feat = pca.n_components_\n",
    "        X_preprocess=self.preprocess.fit_transform(X,y)\n",
    "        print(X_preprocess)\n",
    "        self.mod.fit(X_preprocess, y)\n",
    "        print(y)\n",
    "        self.is_trained = True\n",
    "        \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        This function should provide predictions of labels on (test) data.\n",
    "        Here we just return zeros...\n",
    "        Make sure that the predicted values are in the correct format for the scoring\n",
    "        metric. For example, binary classification problems often expect predictions\n",
    "        in the form of a discriminant value (if the area under the ROC curve it the metric)\n",
    "        rather that predictions of the class labels themselves. For multi-class or multi-labels\n",
    "        problems, class probabilities are often expected if the metric is cross-entropy.\n",
    "        Scikit-learn also has a function predict-proba, we do not require it.\n",
    "        The function predict eventually can return probabilities.\n",
    "        '''\n",
    "    \n",
    "        y=np.random.rand(y)\n",
    "        X_preprocess = self.preprocess.fit_transform(X,y)\n",
    "        y = self.mod.predict(X)\n",
    "\n",
    "\n",
    "        return y\n",
    "\n",
    "    def save(self, path=\"./\"):\n",
    "        pass\n",
    "\n",
    "    def load(self, path=\"./\"):\n",
    "        pass\n",
    "\n",
    "\n",
    "def test():\n",
    "    mod = model()\n",
    "    X_random = np.random.rand(mod.num_train_samples,mod.num_feat)\n",
    "    Y_random = np.random.rand(mod.num_train_samples,)\n",
    "    \n",
    "  \n",
    "    mod.fit(X_random,Y_random)\n",
    "    mod.predict(X_random)\n",
    "    # 1 - cr√©er un data X_random et y_random fictives: utiliser https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.random.rand.html\n",
    "    # 2 - Tester l'entrainement avec mod.fit(X_random, y_random)\n",
    "    # 3 - Test la prediction: mod.predict(X_random)\n",
    "    # Pour tester cette fonction *test*, il suffit de lancer la commande ```python sample_code_submission/model.py```\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24767169, 0.85099997, 0.92406719])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=np.random.rand(3,)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
